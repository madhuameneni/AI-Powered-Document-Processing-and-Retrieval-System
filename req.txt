Document Ingestion: Load a PDF document and process it. 
Vector Store: Use FAISS to create a vector store from the document's content. 
Embeddings: Use Azure OpenAI to generate embeddings for the document's text. 
Retrieval: Implement a retrieval mechanism to find relevant document chunks based on user queries. 
Question-Answering: Use GPT-4 to generate answers from the retrieved document content. 
API: Create a REST API endpoint and test it from outside of the app. 
Tools: Usage of any tools of your choice is allowed. 

Steps involved:
1. get an pdf file and dump it into a vector database.
    - read the file
    - initialize a vector database - FAISS
    - preprocess - extarct the metadata from the pdf
    - convert the extracted data into embeddings 
    - dump into the VD

2. Setup a fast API - which accepts queries
    - initialize the embeddings and a VD
    - init a llm model Open AI Gpt 4 
    - accept the query from the API
        - convert the query into  a embedding 
        - search the q_embedding in the vector database
        - fetch top  similarities 
        - create a promt for openai
        - use the context into and the query to the openai
        - extract the llm model response 
        - return back to the API caller




os.environ["OPENAI_API_TYPE"] = "azure" 
os.environ["AZURE_OPENAI_API_KEY"] = "73b2bf78093c4c60ac189eca4e28d93b" 
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://cog-v25fsk5f6eezo.openai.azure.com/" 
deployment_chat = "gpt-4" 
deployment_embedding = "text-embedding-ada-002" 